"""model_building.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15BEuiTfpYvXV8F5_2aLRo2RrKTauTqEv

<h1 style="color:darkblue;font-family:verdana">PROJECT : Ecommerce Project</h1>


<h2>Project Objective</h2>

This project aims to analyze ecommerce customer data to identify key factors influencing yearly spending. By examining metrics like average session length, time spent on the app and website, and membership duration, we seek insights that will help the company improve customer engagement and increase revenue.avior.

**Dataset Description**

The dataset, titled *Ecommerce Customers*, contains information about the company's customers, including demographic details and engagement metrics. The main features of the dataset are:

- **Customer Information**: The dataset includes basic customer details such as:
  - **Email**: Unique identifier for each customer.
  - **Address**: Location details of the customer.
  - **Color Avatar**: Indicates the preferred avatar color of each customer.

- **Numerical Metrics**: Key numerical columns in the dataset that provide insights into customer engagement and spending:
  - **Avg. Session Length**: Represents the average duration (in minutes) of in-store style advice sessions for customers.
  - **Time on App**: The average time (in minutes) each customer spends on the mobile app.
  - **Time on Website**: The average time (in minutes) each customer spends on the companyâ€™s website.
  - **Length of Membership**: The number of years the customer has been a
 member of the company.


- **Target Variable**
  - **Yearly Amount Spent**: This column represents the total yearly expenditure of each customer (in dollars). It is the key outcome variable, allowing us to analyze factors that may iisfaction and profitability.

<h2 style="color:purple">Import Necessary libraries</h2>
"""

import warnings
warnings.filterwarnings("ignore")

import seaborn as sns
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import plotly.express as px

# Loading the dataset
df = pd.read_csv("Ecommerce_Customers.csv")

"""<h2 style="color:brown">Understanding the dataset</h2>"""

df.head()

df.tail()

df.info()

"""<h1 style="color:purple">EDA ( Exploratory Data Analysis )</h1>

<h2 style="color:brown">Data Preprocessing</h2>
"""

# Handling NUll Values
df.isna().sum().sum()

# Handling Duplicate Values
df.duplicated().sum()

df.Avatar.value_counts()

df.Avatar.nunique()

# Removing Unnecessary Features
# Email,Address,Avatar Because personal data is not required.

df.drop(["Email","Address","Avatar"],axis=1,inplace=True)

df.info()

"""<h2 style="color:brown">Descriptive Statistics</h2>"""

df.describe()

df.skew()

df.kurt()

"""<h1 style="color:purple">Visualization</h1>

<h2 style="color:brown">Uni varient Analysis</h2>

<h3 style="color:darkblue">Boxplot For Outliers Detection</h3>
"""

for column in df.columns:
    fig = px.box(df,x=column,
                 title=f"Box Plot of {column}",
                template="plotly_dark")
    fig.show()

"""**By Analysing the boxplot we can analyse that there are very less number of outliers and those are occured due to seasonal sales or festival offers so dont need to treat the outliers**

<h3 style="color:darkblue">Histogram : To Analyse the Distribution</h3>
"""

for column in df.columns:

    fig = px.histogram(df,x=column,
                       title=f"Histogram for {column}",
                      template="plotly_dark")
    fig.show()

"""<h3 style="color:darkblue">KDE Plot for Data Distribution</h3>"""

for column in df.columns:
    plt.figure(figsize=(4,3))
    sns.kdeplot(data=df,x = column , color ="green")
    plt.title(column)
    plt.show()
    print("\n")

"""<h3 style="color:darkblue">Dist Plot</h3>"""

for column in df.columns:
    plt.figure(figsize=(5,4))
    sns.distplot(x = df[column],color="red" )
    plt.title(column)
    plt.show()

"""<h3 style="color:darkblue">Scatter Plot To Describe Each Feature Distribution</h3>"""

for column in df.columns:
    plt.figure(figsize=(5,5))
    sns.scatterplot(df[column])
    plt.title(column)
    plt.show()

"""<h2 style="color:brown">BI-Varient Analysis</h2>

<h3 style="color:darkblue">Hexbin Plot to Describe Relation B/W Each Feature w.r.t Target Feature</h3>
"""

for column in df.columns:
    if column == "Yearly Amount Spent":
        continue
    plt.figure(figsize=(3,3))
    df.plot.hexbin(x = column,y="Yearly Amount Spent",gridsize=25,reduce_C_function=np.mean)
    plt.show()

"""<h3 style="color:darkblue">PairPlot For Understanding RelationShip Between Each Feature and Target Features</h3>"""

sns.pairplot(df)
plt.title("Pair Plot")
plt.show()

"""<h3 style="color:darkblue">Histogram B/W Each Feature w.r.t Target Variable</h3>"""

for column in df.columns:
    if column == "Yearly Amount Spent":
        continue
    fig = px.histogram(df,x=column,y="Yearly Amount Spent",
                       title = f"{column} w.r.t Yearly Amount Spent",
                       width = 10,
                       template="plotly_dark")
    fig.show()

for column in df.columns:
    if column == "Yearly Amount Spent":
        continue
    plt.figure(figsize=(5,5))
    sns.jointplot(y="Yearly Amount Spent",x=column,data=df,kind="scatter",color="Green")
    print("\n")
    plt.title(f"{column} vs Yearly Amount Spent",y=1.3,color="DarkBlue",size=15)

    plt.show()

"""<h1 style="color:darkblue;font-weight:30;font-family:verdana">Feature Selection</h1>

<h2 style="color:brown">Correlation Matrix</h2>
"""

df.corr()

sns.heatmap(df.corr())

"""<h3>Analysis From Correlation</h3>
<p>From The Correlation Matrix We can conclude that the Target Variable is Mostly Dependent on Following Features</p>

<ol>
    <li>Avg Session Length</li>
    <li>Time on App</li>
    <li>Length of Membership</li>
</ol>

<h2 style="color:brown">PPScore</h2>
"""


import ppscore as pps
matrix = pps.matrix(df)

matrix = matrix[matrix["y"] == "Yearly Amount Spent"]

matrix = matrix.sort_values(by="ppscore",ascending=False)

matrix.drop(24,inplace=True)

plt.bar(matrix["x"], matrix["ppscore"],color="skyblue")
plt.title("PPScore Based Feature Selection")
plt.xlabel("features")
plt.ylabel("Importance")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""<h2 style="color:brown">SelectKBest Method</h2>"""

# Splitting Data Into X,Y
X = df.drop("Yearly Amount Spent",axis=1)
Y = df["Yearly Amount Spent"]

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_regression

selector = SelectKBest(score_func=f_regression,k=4)

selector.fit(X,Y)

selector.get_feature_names_out()

selector.scores_

features = {
    "features":X.columns,
    "Importance":selector.scores_
}
features = pd.DataFrame(features)
features = features.sort_values(by="Importance",ascending=False).reset_index().drop("index",axis=1)

features

plt.bar(features["features"],features["Importance"],data=features)
plt.xlabel("Features")
plt.ylabel("Importance")
plt.xticks(rotation=45)
plt.title("Feature Selection By SelectKBest Method")
plt.tight_layout()
plt.show()

"""<h2 style="color:brown"> RFE (Recurssive Feature Elimination)</h2>"""

from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression

estimator = LinearRegression()
rfe = RFE(estimator= estimator)
rfe.fit(X,Y)

rfe.n_features_

support = rfe.support_

rfe.ranking_

Importance = [1 if i== True else 0 for i in support]

features = {
    "features":X.columns,
    "Importance":Importance
}
features = pd.DataFrame(features)

features.sort_values(by="Importance",ascending=False,inplace=True)

features.reset_index(inplace=True)

features.drop("index",inplace=True,axis=1)

features

# Plotting the Features
plt.bar(features["features"],features["Importance"])
plt.xlabel("features")
plt.ylabel("Importance")
plt.title("RFE Method for Feature Selection")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""<h2 style="color:brown">Tree Based Feature Selection</h2>"""

from sklearn.tree import DecisionTreeRegressor
estimator = DecisionTreeRegressor()
estimator.fit(X,Y)
support = estimator.feature_importances_

features  = {
    "features":X.columns,
    "Importance":support
}
features = pd.DataFrame(features)
features.sort_values(by="Importance",ascending=False,inplace=True)

features.reset_index(inplace=True)

features.drop("index",axis=1,inplace=True)

features

plt.bar(x="features",height="Importance",data=features)
plt.xlabel("features")
plt.ylabel("importance")
plt.title("Feature Selection Using Tree Based")
plt.xticks(rotation=20)
plt.tight_layout()
plt.show()

"""<h1 style="color:darkblue;font-family:verdana"> Selected Features</h1>
<p> By Analysing the feature importances through different feature selection Methods  <br>
The Selected Features are:</p>

<ol>
    <li>Length of Membership</li>
    <li>Time on App</li>
    <li>Avg Session Length</li>
</ol>

<h2 style="color:brown">Solution Based on Data Analysis : </h2>
<div style="text-align:justify;margin-left:30px">
<p style="line-height:3rem">By performing the feature selection through different Methods the Target feature ( Yearly Amount Spent ) is Dependent on <br> <span style="color:green;font-weight:500;font-size:1.1rem;background-color:lightgreen;padding:3px;border-radius:10px">Length of Membership</span>, <span style="color:green;font-weight:500;font-size:1.1rem;background-color:lightgreen;padding:3px;border-radius:10px">Time on App</span> and <span style="color:green;font-weight:500;font-size:1.1rem;background-color:lightgreen;padding:3px;border-radius:10px">Avg Session Length</span> and it is not dependent of <span style="color:black;font-weight:500;font-size:1.1rem;background-color:red;padding:3px;border-radius:10px">Time on Website</span> So the <br> Company need to concentrate on the <span style="color:green;font-weight:500;font-size:1.1rem;background-color:lightgreen;padding:3px;border-radius:10px">Mobile Application</span> and <span style="color:green;font-weight:500;font-size:1.1rem;background-color:lightgreen;padding:3px;border-radius:10px">Sessions </span></p>
</div>

<h1>Model Building</h1>

<h2>Standardizing The Data</h2>
"""

X = df.drop("Yearly Amount Spent", axis =1)
Y = df["Yearly Amount Spent"]

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_df = scaler.fit_transform(X)
X = pd.DataFrame(scaled_df,columns=X.columns)

"""<h2>Splitting the Data into Test and Train</h2>"""

from sklearn.model_selection import train_test_split

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=7)

print(f"X_train : {X_train.shape}")
print(f"Y_train : {Y_train.shape}")
print(f"X_test : {X_test.shape}")
print(f"Y_test : {Y_test.shape}")

"""<h3>Model Evaluation Function</h3>"""

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_absolute_percentage_error

def Evaluate(model):
    model = model
    train_prediction = model.predict(X_train)
    test_prediction = model.predict(X_test)
    r2_train = r2_score(Y_train,train_prediction)
    r2_test = r2_score(Y_test, test_prediction)
    mse_train = mean_squared_error(Y_train,train_prediction)
    mse_test = mean_squared_error(Y_test,test_prediction)
    mae_train = mean_absolute_error(Y_train,train_prediction)
    mae_test = mean_absolute_error(Y_test,test_prediction)
    mape_train = mean_absolute_percentage_error(Y_train,train_prediction)
    print(f"Accuary of Train:{np.round(r2_train,3)*100}%")
    print(f"Accuray of Test:{np.round(r2_test,3)*100}%")
    mape_test  = mean_absolute_percentage_error(Y_test,test_prediction)
    print(f"Mean_squared_error of Train : {np.round(mse_train,3)}")
    print(f"Mean_squared_error of Test : {np.round(mse_test,3)}")
    print(f"Mean_absolute_error of Train : {np.round(mae_train,3)}")
    print(f"Mean_absolute_error of Test : {np.round(mae_test,3)}")
    print(f"Mean_absolute_percentage_error of Train : {np.round(mape_train,3)}")
    print(f"Mean_absolute_percentage_error of Test : {np.round(mape_test,3)}")
    evaluation = {
        "model":type(model).__name__,
        "r2_score_train":np.round(r2_train,3)*100,
        "r2_score_test":np.round(r2_test,3)*100,
        "mse_train":np.round(mse_train,3),
        "mse_test":np.round(mse_test,3),
        "mae_train":np.round(mae_train,3),
        "mae_test": np.round(mae_test,3),
        "mape_train": np.round(mape_train,3),
        "mape_test":np.round(mape_test,3)
    }
    return evaluation

"""<h3 style="color:darkblue;font-family:verdana">LinearRegression Model</h3>"""

from sklearn.linear_model import LinearRegression
linear_model = LinearRegression()
linear_model.fit(X_train,Y_train)

linear_model_metrics = Evaluate(linear_model)

"""<h3 style="color:darkblue;font-family:verdana">DecisionTree Regression Model</h3>"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV
estimator = DecisionTreeRegressor()
params= {
    "min_samples_split":[3,4,5,6,7],
    "max_depth":[5,6,7,8,9,10,11]
}
grid_search = GridSearchCV(estimator = estimator, param_grid = params,n_jobs =-1,verbose=1)

grid_search.fit(X_train,Y_train)

decision_tree_model = grid_search.best_estimator_

decision_tree_metrics = Evaluate(decision_tree_model)

"""<h3 style="color:darkblue;font-family:verdana">Random_Forest_Regression Model</h3>"""

from sklearn.ensemble import RandomForestRegressor
estimator = RandomForestRegressor()
params = {
    "n_estimators":[10,20,30,40,50,100,200],
    "min_samples_split":[3,4,5,6,7],
    "max_depth":[6,7,8,9,10,11,12]
}
grid_search = GridSearchCV(estimator = estimator,param_grid = params , n_jobs=-1,scoring="r2",verbose=1)

grid_search.fit(X_train,Y_train)

grid_search.best_params_

random_forest_model = grid_search.best_estimator_

random_forest_metrics = Evaluate(random_forest_model)

"""<h3 style="color:darkblue;font-family:verdana">Bagging_Regression Model</h3>"""

from sklearn.ensemble import BaggingRegressor
estimator = BaggingRegressor()
params={
    "n_estimators":[50,100,120,150,200],
    "max_samples":[1,2,3,4,5,6,7],
    "max_features":[1,2,3,4]
}
grid_search = GridSearchCV(estimator = estimator,param_grid = params,scoring="r2",n_jobs=-1,verbose = 1)

grid_search.fit(X_train,Y_train)

grid_search.best_params_

bagging_model = grid_search.best_estimator_

bagging_metrics = Evaluate(bagging_model)

"""<h3 style="color:darkblue;font-family:verdana">AdaBoost_Regression Model</h3>"""

from sklearn.ensemble import AdaBoostRegressor
estimator = AdaBoostRegressor()
params = {
    "estimator":[decision_tree_model],
    "n_estimators":[50,100,120,150,200,250],
    "learning_rate":[1e-1,1e-2,1e-3,1e-4]
}
grid_search = GridSearchCV(estimator=estimator,param_grid=params,n_jobs=-1,verbose=1)

grid_search.fit(X_train,Y_train)

AdaBoost_model = grid_search.best_estimator_

AdaBoost_metrics = Evaluate(AdaBoost_model)

"""<h3 style="color:darkblue;font-family:verdana">KNN_Regression Model</h3>"""

from sklearn.neighbors import KNeighborsRegressor
estimator = KNeighborsRegressor()
params = {
    "n_neighbors":[3,4,5,6,7,8,9,10],
}
grid_search = GridSearchCV(estimator = estimator,param_grid=params,n_jobs=-1,verbose=1,scoring= "r2")

grid_search.fit(X_train,Y_train)

grid_search.best_params_

knn_model = grid_search.best_estimator_

knn_metrics = Evaluate(knn_model)

"""<h3 style="color:darkblue;font-family:verdana">XGBoost Regression Model</h3>"""

from xgboost import XGBRegressor
estimator = XGBRegressor()
params = {
    "n_estimators":[50,100,120,150,200,220],
    "max_depth":[5,6,7,8,9,10,11],
    "learning_rate":[1e-1,1e-2,1e-3,1e-4],
}
grid_search = GridSearchCV(estimator= estimator,param_grid = params,n_jobs=-1,scoring="r2",verbose=1)

grid_search.fit(X_train,Y_train)

grid_search.best_params_

xgb_model = grid_search.best_estimator_

xgb_metrics = Evaluate(xgb_model)

"""<h2>Comparing the Models</h2>"""

comparison_table = [
    linear_model_metrics,
    decision_tree_metrics,
    random_forest_metrics,
    bagging_metrics,
    AdaBoost_metrics,
    xgb_metrics,
    knn_metrics
]

comparision_table = pd.DataFrame(comparison_table)

comparision_table.sort_values(by="r2_score_test", ascending=False).reset_index().drop("index",axis=1)

